![Group 8 (1)](https://github.com/garick161/SiburChallenge2023/assets/114688542/5a26d18d-36a7-4787-b7ac-3daffc9a90aa)

Данный кейс представлен нефтехимической компанией Сибур на чемпионате Sibur Challenge 2023 по направлению "Видеоаналитика".\
Более подробно вы можете ознакомится с материалами на платформе AI Today. Вся информация находится в свободном доступе.

https://platform.aitoday.ru/event/9\

__*Цитата из условия задачи:*__

>Необходимо создать модель распознавания действий с вагон-цистерной на эстакаде, которая пошагово отслеживает жизненный цикл вагон-цистерны (въезд на эстакаду, подготовка к сливу, слив, подготовка к отъезду, выезд поезда и т. д.).

>Для решения задачи вам предоставлен набор видеороликов, каждый из которых относится к одному из четырех классов:

>`bridge_down` - класс "мостик опущен",

>`bridge_up` - класс "мостик поднят",

>`no_action` - класс "нет операций в кадре",

>`train_in_out` - класс "въезд/выезд цистерны".

>В одном ролике может быть ровно один класс. Особенность задачи заключается в том, что модель распознавания не должна требовать дорогой и долгой дотренировки или сбора дополнительных данных для развертывания системы видеоаналитики в новых локациях. Кроме того, модель должна быть устойчива к потере связи, т. е. пропущенным кадрам в видео.

>Метрика - F1 (macro).

Всего представлено 496 видеороликов дительностью не более 10 секунд с соотношением:\
`bridge_down` - 306\
`bridge_up` - 75\
`no_action` - 49\
`train_in_out` - 66

Формат видеороликов выглядит следующим образом
![readme_0_79](https://github.com/garick161/SiburChallenge2023/assets/114688542/b4020ee5-067e-426c-9ea8-b5f894c71459)

![readme_80_159](https://github.com/garick161/SiburChallenge2023/assets/114688542/3541e64c-0283-4e90-a793-6d02e2eb8f46)

![readme_160_239](https://github.com/garick161/SiburChallenge2023/assets/114688542/0e57a926-235e-461f-96d5-85bb11e86975)

Несмотря на то что ролики всего четырех классов, наполнение внутри каждого класса достаточно разообразно. Разные виды локаций, разные углы обзора камеры, различное освещение и даже тип цистерн отличается.

# Описание этапов разработки модели
Часть №1\
https://nbviewer.org/github/garick161/SiburChallenge2023/blob/master/notebooks/research_review_part1.ipynb
- Первая модель / Анализ / Предварительные выводы
- Подготовка качественной обучающей выборки. Автоматизированный подход к семплированию видео файлов. Основная идея: создать максимально репрезентативную выборку, в тоже време небольшого размера
- Выбор и разметка объектов для выполнения ObjectDetection
- Обучение YOLO8n

Часть №2\
https://nbviewer.org/github/garick161/SiburChallenge2023/blob/master/notebooks/research_review_part2.ipynb
- Разбор алгоритма принятия решения на основе ObjectDetection
- Подход к логированию работы модели
- Результаты модели

# PipeLine проекта
![pipeline_photo](https://github.com/garick161/SiburChallenge2023/assets/114688542/67ecfe63-f925-4777-98e5-8c61f227f5e0)

# Файловая структура проекта
`notebooks` - содержит файлы jupiter notebooks
- `research_review.jpynb` - Изложение хода иследования  
- `yolo8_train.jpynb` - Обучение модели YOLO 8n на платформе Google_Colab

`scripts` - основной модуль проекта. Содержит набор скриптов. Перечисляться будут согласно логической связи.
- `contrast_increase.py` - повышает контрастность изображений
- `frames2emb.py` - выполняет преобразование video_file -> one_frame -> embedding. \
  Фото сохраняются в папку `images_for_emb` согласно классам. Эмбеддинги сохраняются в датафреймы по классам. Также сохраняются названия, пути к видео и к фото для дальнейшей работы. Сохраняется четкое соответвие video_name -> embedding
- `find_subclass.py` - Разделяет видеофайлы из одного класса на подклассы для дальнейшего сэмплирования. Похожие/идентичные видео в один подкласс. Схожеть определяется на основе эмбеддингов
- `show_subclasses.py` - для визуальной оценки качества разбиения на подклассы
- `sampling_images.py` - семплирование видео для получения тренировочной и тестовой выборки на основании подклассов
- `get_train_out_frames.py` - подготавливает фото из класса `train_in_out` для дальнейшей разметки
- `check_result_model_with_logs.py` - скрипт для получения предсказания по одному видеофайлу с функцией логирования
- `check_result_model_without_logs.py` - скрипт для получения предсказания по одному видеофайлу без логирования
- `checking_batch_videos.py` - предсказания для массива видеофайлов. Использует скрипт `check_result_model_without_logs.py`
- `show_results_model.py` - массив видеофайлов -> фотографии с частотой 1 кадр в секунду с нанесением bounding_boxeses от YOLO 8n
- `check_one_video.py` - один видеофайл -> одна фотографии с нанесением bounding_boxeses от YOLO 8n

`dataframes` - содержит файлы в формате ".csv" для хранения, администрирования и проведения агрегаций данных

`logs` - содержит файлы с расширением ".log" с логированием эскпериментов

`images_for_emb` - содержит фотографии по классам для получения эмбеддингов

`images_for_labeling` - содержит фотографии для дальнейшей разметки

`weights` - содержит различные веса для модели YOLO 8n

`prepair_dataset` - содержит исходные видеофайлы, распределенные по классам

`root`
- `requiremets.txt`

# Входе проекта использовались:
- Object Detection - `YOLO 8n` - https://docs.ultralytics.com/
- Разметка фотографий - `Roboflow` - https://roboflow.com/
- Получение эмбеддингов - `Resnet18` - https://pytorch.org/hub/pytorch_vision_resnet/
- Трансформации изображений - `OpenCV` - https://opencv.org/\

Со всем списком используемых библиотек вы можете ознакомится в файле `requirements.txt`

# Результаты
- Для обучения использовались кадры из 255 видео (train)
- При тестировании на 241 видеофайле (test) при 10 кадров с ролика модель показала качество F1(macro) = 0.98
- Скорость обаботки одного видеофайла на процессоре Intel Core i5-8250U: 2,5 - 3,2 секунд

# Что можно еще изучить?
- Используя найденый способ сэмлирования, еще снизить размер обучающей выборки (до 30%). Проверить качество и стабильность работы модели
- Протестировать модель на меньшем количестве кадров с ролика. Проверить стабильности работы при разрыве более чем в 2 секунды
- Найти способ оптимизации обрабоки видео. Скорость обработки одного ролика 2,5 - 3,2 секунды (10 кадров). Скорость Object Detection одного фрейма 100 - 150 мс. 10 фреймов = 1,5 секунды. Выяснить на что уходит оставшееся время?

# Выводы
- Сочетание простой модели YOLO 8n и обычной логики показали неплохой результат.
- Подход к сэмплированию - рабочий. Он позволяет не только снизить количество фотографий для разметки, но повышает качество тренировочной выборки. Данный подход можно использовать и в других задачах видеоаналитики.
- Вся модель в целом может быть отправной точкой в оптимизации логистики. Собрав данные с разных локаций, можно определить сколько обычно уходит времени на определенные операции. Выяснить почему на некоторых локациях операции занимают больше времени, чем на других. Увидеть проблемы, наладить процессы. Это позволить уменьшить простой подвижного состава и снизить расходы на его аренду.

#  Слова благодарности
Хочу выразить огромную благодарность всем организаторам этого чемпионата! Работа на кейсом доставила удовольствие. Входе выполнения пришлось изучить новые полезные инструменты, освоить тонкости на практике. Сформировался подход для решения такого типа задач, который можно будет использовать в будущем. 

![readme_last_line1](https://github.com/garick161/SiburChallenge2023/assets/114688542/0318fdb9-fd22-45ef-8ae5-c3a10db09265)

![readme_last_line2](https://github.com/garick161/SiburChallenge2023/assets/114688542/dc8a1139-2e62-4034-a048-818613bb1a12) 

